---
layout: post
title: 学习AI之 术语
date: 2025-08-11 21:56:23 +0800
category: AI
---

| 术语 | 缩写 | 中文名称 | 含义 | 备注| 
| --- | --- | --- | --- | --- |
| Deep learning | DL | 深度学习 | | |
| Machine learning | ML | 机器学习 |  The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps. |
| Label | |标记 | The data that we’re trying to predict, such as “dog” or “cat” | |
| Architecture | | 模型的模板 | The template of the model that we’re trying to fit; i.e., the actual mathematical function that we’re passing the input data and parameters to | |
| Model  | |模型 | The combination of the architecture with a particular set of parameters | |
| Parameters | | 参数 | The values in the model that change what task it can do and that are updated through model training | |
| Fit | | 训练 | Update the parameters of the model such that the predictions of the model using the input data match the target labels | |
| Train | | 训练，同fit | A synonym for fit | |
| Pretrained model | | 提前训练好的模型 | A model that has already been trained, generally using a large dataset, and will be fine-tuned | |
| Fine-tune | |微调 | Update a pretrained model for a different task | |
| Epoch | | 一轮 |One complete pass through the input data | |
| Loss | | 损失 | A measure of how good the model is, chosen to drive training via SGD | |
| Metric | | 度量| A measurement of how good the model is using the validation set, chosen for human consumption | |
| Validation set | | 验证集 | A set of data held out from training, used only for measuring how good the model is | |
| Training set | |训练集 | The data used for fitting the model; does not include any data from the validation set | |
| Overfitting | |过度拟合 | Training a model in such a way that it remembers specific features of the input data, rather than generalizing well to data not seen during training | |
| Convolutional neural network | CNN | 卷积神经网络 | a type of neural network that works particularly well for computer vision tasks | |
| Natural language processing | NLP | 自然语言处理 | | | |
| Graphics Processing Unit | GPU |图像处理单元 | A special kind of processor in your computer that can handle thousands of single tasks at the same time, especially designed for displaying 3D environments on a computer for playing games. | |
| Jupyter Notebook | |  | A piece of software that allows you to include formatted text, code, images, videos, and much more, all within a single interactive document.| |
| Regression | |回归 |A regression model is one that attempts to predict one or more numeric quantities, such as a temperature or a location.  | |
| Classification | |分类 | A classification model is one that attempts to predict a class, or category. That is, it’s predicting from a number of discrete possibilities, such as “dog” or “cat.”  | |
| Transfer Learning | |迁移学习 | Using a pretrained model for a task different from what it was originally trained for.| |
| Tabular | |表格数据 | Data that is in the form of a table, such as from a spreadsheet, database, or a comma-separated values (CSV) file. | |
| Datasets | |数据集 | Food for Models | |
| DataLoaders | |数据加载器 | A fastai class that stores multiple DataLoader objects you pass to it | fastai |
| Learning Rate| LR | | The size of the step we take when applying SGD to update the parameters of the model. | |
| Activations | | | Numbers that are calculated (both by linear and nonlinear layers) | |
| Parameters |||Numbers that are randomly initialized, and optimized (that is, the numbers that define the model)|
| Rank-0 | | | scalar| |
| Rank-1 | | | vector | |
| Rank-2 | | | matrix | |
| ReLU | | | Function that returns 0 for negative numbers and doesn’t change positive numbers. | |
| Mini-batch | | | A small group of inputs and labels gathered together in two arrays. A gradient descent step is updated on this batch (rather than a whole epoch). | |
| Forward pass  | | | Applying the model to some input and computing the predictions. | |
| Gradient | | |The derivative of the loss with respect to some parameter of the model. | |
| Backward pass | | | Computing the gradients of the loss with respect to all model parameters. | |
| Gradient descent | | | Taking a step in the direction opposite to the gradients to make the model parameters a little bit better. | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
